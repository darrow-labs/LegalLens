{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
        "codemirror_mode": {
        "name": "ipython",
        "version": 3
       },
       "file_extension": ".py",
       "mimetype": "text/x-python",
       "name": "python",
       "nbconvert_exporter": "python",
       "pygments_lexer": "ipython3",
       "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval==1.2.2 evaluate==0.4.1\n",
        "!pip install accelerate==0.21.0 -U\n",
        "!pip install transformers==4.31.0 datasets==2.15.0"
      ],
      "metadata": {
        "id": "YQynJDhPUXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    # Unpack nested dictionaries\n",
        "    final_results = {}\n",
        "    for key, value in results.items():\n",
        "        if isinstance(value, dict):\n",
        "            for n, v in value.items():\n",
        "                final_results[f\"{key}_{n}\"] = v\n",
        "        else:\n",
        "            final_results[key] = value\n",
        "    return final_results\n",
        "\n",
        "\n",
        "def get_label_list(dataset):\n",
        "    label_set = set()\n",
        "    for data in dataset:\n",
        "        labels = data[\n",
        "            \"ner_tags\"\n",
        "        ]  # Adjust this field name based on your dataset structure\n",
        "        label_set.update(labels)\n",
        "    return list(label_set)\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(examples, tokenizer, label_to_id):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    labels = []\n",
        "    for i, example_labels in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        last_word_id = None\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_id != last_word_id:\n",
        "                label_id = label_to_id.get(example_labels[word_id], -100)\n",
        "                label_ids.append(label_id)\n",
        "            else:\n",
        "                label_ids.append(\n",
        "                    -100\n",
        "                )  # or label_ids.append(label_id) if you want to label sub-tokens\n",
        "            last_word_id = word_id\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "UG4p-1GfRZBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "model_name = \"roberta-base\"  # You can replace this with any model you prefer\n",
        "dataset_name = \"darrow-ai/LegalLensNER\"  # Replace with your dataset\n",
        "\n",
        "# Load dataset\n",
        "raw_datasets = load_dataset(dataset_name)\n",
        "\n",
        "raw_datasets = raw_datasets.map(\n",
        "    lambda x: {\n",
        "        \"tokens\": ast.literal_eval(x[\"tokens\"]),\n",
        "        \"ner_tags\": ast.literal_eval(x[\"ner_tags\"]),\n",
        "    }\n",
        ")\n",
        "\n",
        "label_list = get_label_list(\n",
        "    raw_datasets[\"train\"]\n",
        ")  # Assuming 'train' split exists and contains the labels\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    add_prefix_space=True,\n",
        "    use_fast=True,\n",
        ")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name, num_labels=len(label_list)\n",
        ")\n",
        "\n",
        "# Create label_to_id mapping\n",
        "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "# Tokenization and alignment of labels\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    lambda x: tokenize_and_align_labels(x, tokenizer, label_to_id), batched=True\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Pxmut40LEIEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()"
      ],
      "metadata": {
        "id": "q_AQKqKvVmhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{k: v for k, v in eval_result.items() if \"f1\" in k.lower()}"
      ],
      "metadata": {
        "id": "PDSqPi2jV9oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPf5RJF9USSk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
