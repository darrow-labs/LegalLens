{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4cce09b-3ea7-4f9d-a604-08383959360d",
     "showTitle": false,
     "title": ""
    },
    "id": "Gc2gcBOudc59"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.31.0 datasets==2.15.0 trl==0.7.10 peft==0.7.1 bitsandbytes==0.42.0 flash-attn==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abf1323d-fc00-4479-892d-bc17004b9ccd",
     "showTitle": false,
     "title": ""
    },
    "id": "x8oaVCUFtNI7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import datasets\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "083f221c-2a90-4eea-a1dc-bc2c402c9a0e",
     "showTitle": false,
     "title": ""
    },
    "id": "JI-ywPXT3Vh3"
   },
   "outputs": [],
   "source": [
    "pretrained_ckpt = \"tiiuae/falcon-7b\"\n",
    "\n",
    "legal_type = \"consumer_protection\"\n",
    "\n",
    "experiment_run = 1\n",
    "lora_r = 64\n",
    "epochs = 20\n",
    "dropout = 0.25\n",
    "\n",
    "results_dir = f\"experiments/falcon_nli-{legal_type}_epochs-{epochs}_rank-{lora_r}_dropout-{dropout}_expRun-{str(experiment_run)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b4b34fd-4f97-4d69-b295-d63374a60eb4",
     "showTitle": false,
     "title": ""
    },
    "id": "56mV39hVdsky"
   },
   "outputs": [],
   "source": [
    "TRAINING_PROMPT = \"\"\"###Premise:{premise} ###Hypothesis:{hypothesis} ###Label:{label}\"\"\"\n",
    "INFERENCE_PROMPT = \"\"\"###Premise:{premise} ###Hypothesis:{hypothesis} ###Label:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "233cc83a-80b0-48d0-9480-72c14bf5b0e3",
     "showTitle": false,
     "title": ""
    },
    "id": "6WLCMM0w3W_K"
   },
   "outputs": [],
   "source": [
    "def get_train_nli_data(legal_type: str) -> pd.DataFrame:\n",
    "    justice_lens_dataset = datasets.load_dataset(\"darrow-ai/LegalLensNLI\")\n",
    "\n",
    "    df = (\n",
    "        justice_lens_dataset[\"train\"]\n",
    "        .filter(lambda example: example[\"legal_act\"] != legal_type)\n",
    "        .to_pandas()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_test_nli_data(legal_type: str) -> pd.DataFrame:\n",
    "    justice_lens_dataset = datasets.load_dataset(\"darrow-ai/LegalLensNLI\")\n",
    "\n",
    "    df = (\n",
    "        justice_lens_dataset[\"train\"]\n",
    "        .filter(lambda example: example[\"legal_act\"] == legal_type)\n",
    "        .to_pandas()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_instruction(premise, hypothesis, label, is_train=False):\n",
    "    if is_train:\n",
    "        instruction = TRAINING_PROMPT.format(\n",
    "            premise=premise, hypothesis=hypothesis, label=label\n",
    "        )\n",
    "    else:\n",
    "        instruction = INFERENCE_PROMPT.format(\n",
    "            premise=premise,\n",
    "            hypothesis=hypothesis,\n",
    "        )\n",
    "\n",
    "    return instruction\n",
    "\n",
    "\n",
    "def get_instructions(df, is_train=False):\n",
    "    instructions = []\n",
    "    for idx, row in df.iterrows():\n",
    "        premise = row[\"premise\"]\n",
    "        hypothesis = row[\"hypothesis\"]\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        prompt = prepare_instruction(premise, hypothesis, label, is_train=is_train)\n",
    "\n",
    "        instructions.append(prompt)\n",
    "\n",
    "    return instructions\n",
    "\n",
    "\n",
    "def predict_one_sample(prompt, model, tokenizer):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_new_tokens=250,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            temperature=0.01,\n",
    "        )\n",
    "        output = tokenizer.batch_decode(\n",
    "            outputs.detach().cpu().numpy(), skip_special_tokens=True\n",
    "        )[0][len(prompt) :]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab4580dc-20dd-4e80-8a5d-2abaaebde4bf",
     "showTitle": false,
     "title": ""
    },
    "id": "hHBoqH3T2xM_"
   },
   "outputs": [],
   "source": [
    "df_train = get_train_nli_data(legal_type=legal_type)\n",
    "train_instructions = get_instructions(df_train, is_train=True)\n",
    "train_dataset = datasets.Dataset.from_pandas(\n",
    "    pd.DataFrame(data={\"instructions\": train_instructions})\n",
    ")\n",
    "\n",
    "df_test = get_test_nli_data(legal_type=legal_type)\n",
    "test_instructions = get_instructions(df_test, is_train=False)\n",
    "test_dataset = datasets.Dataset.from_pandas(\n",
    "    pd.DataFrame(data={\"instructions\": test_instructions})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abfa496f-da54-4b38-ba08-3ae4d967dee1",
     "showTitle": false,
     "title": ""
    },
    "id": "SKc-buH8tX_G"
   },
   "outputs": [],
   "source": [
    "use_flash_attention = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_ckpt)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Getting PEFT method\")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_alpha=32,\n",
    "    r=lora_r,\n",
    "    lora_dropout=dropout,\n",
    "    target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model_name_or_path = pretrained_ckpt\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_ckpt,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir=results_dir,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=epochs,\n",
    "    logging_dir=f\"{results_dir}/logs\",\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    ")\n",
    "\n",
    "print(f\"training_args = {training_args}\")\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"instructions\",\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "train_loss = trainer_stats.training_loss\n",
    "print(f\"Training loss:{train_loss}\")\n",
    "\n",
    "peft_model_id = f\"{results_dir}/assets\"\n",
    "trainer.model.save_pretrained(peft_model_id)\n",
    "tokenizer.save_pretrained(peft_model_id)\n",
    "\n",
    "with open(f\"{results_dir}/results.pkl\", \"wb\") as handle:\n",
    "    run_result = [\n",
    "        epochs,\n",
    "        lora_r,\n",
    "        dropout,\n",
    "        train_loss,\n",
    "    ]\n",
    "    pickle.dump(run_result, handle)\n",
    "print(\"Experiment over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "561a0de8-301c-4506-ba33-c0a2d9ff5b7b",
     "showTitle": false,
     "title": ""
    },
    "id": "UF56V-Ri2F6M"
   },
   "outputs": [],
   "source": [
    "peft_model_id = os.path.join(results_dir, \"assets\")\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Do few-shot prompting\n",
    "responses = []\n",
    "labels = df_test[\"label\"].to_list()\n",
    "\n",
    "save_dir = os.path.join(results_dir, \"inference\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for prompt in tqdm(test_instructions):\n",
    "    response = predict_one_sample(prompt, model, tokenizer)\n",
    "    responses.append(response)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"micro_f1\": f1_score(labels, responses, average=\"micro\"),\n",
    "    \"macro_f1\": f1_score(labels, responses, average=\"macro\"),\n",
    "    \"micro_precision\": precision_score(labels, responses, average=\"micro\"),\n",
    "    \"micro_recall\": recall_score(labels, responses, average=\"micro\"),\n",
    "    \"macro_precision\": precision_score(labels, responses, average=\"macro\"),\n",
    "    \"macro_recall\": recall_score(labels, responses, average=\"macro\"),\n",
    "    \"accuracy\": accuracy_score(labels, responses),\n",
    "}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89256c35-f4f5-4721-a683-506d7c869b47",
     "showTitle": false,
     "title": ""
    },
    "id": "gpf7Yn3ShRat"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LegalLensNLI",
   "widgets": {}
  },
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
